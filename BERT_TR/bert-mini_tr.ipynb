{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, EvalPrediction\n",
    "from datasets import Dataset\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data\n",
    "df = pd.read_csv(\"data.csv\")  \n",
    "df['text'] = df['text'].apply(lambda x: re.sub(r\"[^a-zA-ZığüşöçİĞÜŞÖÇ ]\",\"\",x).lower())\n",
    "# Split into train and test sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)  # random_state for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c57309d42575421f86b8f31c2cab7623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2898eea2c245e288324609d8965a00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4b63b4547104f689400e1102540d867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/251k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c999babed545be99e8fb1be8758c18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6243 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52439380ee504d31a7d0ebd9cfe48d04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-cased\") # Türkçe BERT modelini kullan\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Fine-tuning\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"dbmdz/bert-base-turkish-cased\", num_labels=len(set(df[\"label\"]))) # Türkçe BERT modelini kullan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    num_train_epochs=5,  # Adjust as needed\n",
    "    per_device_train_batch_size=8,  # Adjust based on your GPU memory\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fa37b0140ee4d5e81246b09f8e40ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3905 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.411, 'grad_norm': 0.07530378550291061, 'learning_rate': 5e-05, 'epoch': 0.64}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define a function to compute metrics\n",
    "def compute_metrics(pred: EvalPrediction):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets,\n",
    "    eval_dataset=tokenized_datasets, # Using same dataset for eval in this example\n",
    "    compute_metrics=compute_metrics, # Pass the metrics function to the Trainer\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18186151544a45bda1afb1fe91027c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/640 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "506a51099abf4a5c8127fae237f3cdae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9265625\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save the model\n",
    "trainer.save_model(\"./fine_tuned_bert0\")\n",
    "\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "tokenized_test_dataset = test_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Evaluate on the test dataset\n",
    "results = trainer.predict(tokenized_test_dataset)\n",
    "predicted_labels = np.argmax(results.predictions, axis=1)\n",
    "accuracy = accuracy_score(test_df[\"label\"], predicted_labels)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>the only reason why im giving  a five star rat...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>another day and another review for vodaphone d...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>we have att fiber optics home internet we have...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>i recently wrote a review of assurant the comp...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>att has the worst customer service ive ever ex...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>my wife and i shared a grandfathered data plan...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>this is the second part of a review without go...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>trying to interact with customer service is in...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>well i had to hook up a line just to see if i ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>im trying to figure why so many morans are giv...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>asked tamworth shop to help with update of wha...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>the tmobile store in hermitage on lebanon rd a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>after being a devoted tmobile customer for ove...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754</th>\n",
       "      <td>ive tried orange vodafone tmobile and left the...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>on  my mother and i walked in to the tmobile s...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>our reviews dont seem to matter but hear goes ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>really bad  why  i did a new broadband contrac...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3054</th>\n",
       "      <td>i ordered a phone via the my o app as i was du...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2620</th>\n",
       "      <td>man theres a big difference between spectrum a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>absolute rubbish paying  pound a month for unl...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>have been with tmobile for  months customer se...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907</th>\n",
       "      <td>i have to say i was not with o for all that lo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3015</th>\n",
       "      <td>i recently transferred  lines from verizon to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>my wife and i have been customers of vodafone ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>i have been a customer of this company since  ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098</th>\n",
       "      <td>originally i posted a review here about troubl...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>this was a while ago att bought out by indian ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>for  years we have had sky broadband with no i...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>shocking customer supportterrible broadband sp...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>couldnt even use the data for  months cant mak...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3153</th>\n",
       "      <td>please let everybody that doesnt know should k...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3051</th>\n",
       "      <td>minus its disappointing that you must give at ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2943</th>\n",
       "      <td>these people are god sent seriously they work ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2815</th>\n",
       "      <td>i ordered a gb unlimited minutes  texts simonl...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>i was recently assisted by bilaal in the strat...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>what a complete joke of a company there turnin...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2881</th>\n",
       "      <td>purchased an iphone  pro online at vodafone th...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>okay going to take a moment to vent and to sav...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3159</th>\n",
       "      <td>on sat nov  i went to the tmobile store on twe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>on august th i went to the store in gastonia o...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>they offered broadband and landline the broadb...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3012</th>\n",
       "      <td>i have had an incredible experience with tmobi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>i have been trying to deal with adding lines a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>i was here two times associates do not like us...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2846</th>\n",
       "      <td>beware att did a bait and switch on my uverse ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>i just spent about half an hour waiting to get...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>our old phone carrier shut down so we were for...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label  predicted\n",
       "2895  the only reason why im giving  a five star rat...      1          0\n",
       "1289  another day and another review for vodaphone d...      0          1\n",
       "1590  we have att fiber optics home internet we have...      0          1\n",
       "564   i recently wrote a review of assurant the comp...      0          1\n",
       "594   att has the worst customer service ive ever ex...      0          1\n",
       "1446  my wife and i shared a grandfathered data plan...      0          1\n",
       "1151  this is the second part of a review without go...      0          1\n",
       "51    trying to interact with customer service is in...      0          1\n",
       "63    well i had to hook up a line just to see if i ...      0          1\n",
       "2440  im trying to figure why so many morans are giv...      1          0\n",
       "120   asked tamworth shop to help with update of wha...      0          1\n",
       "178   the tmobile store in hermitage on lebanon rd a...      0          1\n",
       "457   after being a devoted tmobile customer for ove...      0          1\n",
       "2754  ive tried orange vodafone tmobile and left the...      1          0\n",
       "678   on  my mother and i walked in to the tmobile s...      0          1\n",
       "218   our reviews dont seem to matter but hear goes ...      0          1\n",
       "45    really bad  why  i did a new broadband contrac...      0          1\n",
       "3054  i ordered a phone via the my o app as i was du...      1          0\n",
       "2620  man theres a big difference between spectrum a...      1          0\n",
       "149   absolute rubbish paying  pound a month for unl...      0          1\n",
       "691   have been with tmobile for  months customer se...      0          1\n",
       "2907  i have to say i was not with o for all that lo...      1          0\n",
       "3015  i recently transferred  lines from verizon to ...      1          0\n",
       "1221  my wife and i have been customers of vodafone ...      0          1\n",
       "246   i have been a customer of this company since  ...      0          1\n",
       "3098  originally i posted a review here about troubl...      1          0\n",
       "798   this was a while ago att bought out by indian ...      0          1\n",
       "196   for  years we have had sky broadband with no i...      0          1\n",
       "166   shocking customer supportterrible broadband sp...      0          1\n",
       "598   couldnt even use the data for  months cant mak...      0          1\n",
       "3153  please let everybody that doesnt know should k...      1          0\n",
       "3051  minus its disappointing that you must give at ...      1          0\n",
       "2943  these people are god sent seriously they work ...      1          0\n",
       "2815  i ordered a gb unlimited minutes  texts simonl...      1          0\n",
       "1381  i was recently assisted by bilaal in the strat...      0          1\n",
       "1563  what a complete joke of a company there turnin...      0          1\n",
       "2881  purchased an iphone  pro online at vodafone th...      1          0\n",
       "1537  okay going to take a moment to vent and to sav...      0          1\n",
       "3159  on sat nov  i went to the tmobile store on twe...      1          0\n",
       "1456  on august th i went to the store in gastonia o...      0          1\n",
       "111   they offered broadband and landline the broadb...      0          1\n",
       "3012  i have had an incredible experience with tmobi...      1          0\n",
       "472   i have been trying to deal with adding lines a...      0          1\n",
       "29    i was here two times associates do not like us...      0          1\n",
       "2846  beware att did a bait and switch on my uverse ...      1          0\n",
       "420   i just spent about half an hour waiting to get...      0          1\n",
       "1468  our old phone carrier shut down so we were for...      0          1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_df = test_df\n",
    "diff_df['predicted'] = predicted_labels\n",
    "diff_df = diff_df[diff_df['label'] != diff_df['predicted']]\n",
    "diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_df.to_csv(\"false_predictions.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test_df\n",
    "df['predicted'] = predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>312</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     1    0\n",
       "1  312   31\n",
       "0   16  281"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(df['label'], df['predicted'])\n",
    "\n",
    "# Confusion matrix'i daha okunaklı hale getirmek için bir DataFrame'e dönüştürün\n",
    "cm_df = pd.DataFrame(cm, index=df['label'].unique(), columns=df['label'].unique())\n",
    "\n",
    "# Confusion matrix'i görüntüleyin\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93       343\n",
      "           1       0.90      0.95      0.92       297\n",
      "\n",
      "    accuracy                           0.93       640\n",
      "   macro avg       0.93      0.93      0.93       640\n",
      "weighted avg       0.93      0.93      0.93       640\n",
      "\n",
      "Accuracy: 0.9265625\n",
      "Precision: [0.95121951 0.90064103]\n",
      "Recall: [0.90962099 0.94612795]\n",
      "F1-score: [0.92995529 0.9228243 ]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Sınıflandırma raporunu yazdır\n",
    "print(classification_report(df['label'], df['predicted']))\n",
    "\n",
    "# Her sınıf için metrikleri hesapla\n",
    "accuracy = accuracy_score(df['label'], df['predicted'])\n",
    "precision = precision_score(df['label'], df['predicted'], average=None)\n",
    "recall = recall_score(df['label'], df['predicted'], average=None)\n",
    "f1 = f1_score(df['label'], df['predicted'], average=None)\n",
    "\n",
    "# Sonuçları yazdır\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 1\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"./fine_tuned_bert0\")\n",
    "def preprocess_text(text):\n",
    "    return tokenizer(text, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "import torch\n",
    "\n",
    "def predict(text):\n",
    "    inputs = preprocess_text(text)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "    return predictions.item()\n",
    "\n",
    "# Example usage\n",
    "text =\"\"\n",
    "prediction = predict(text)\n",
    "print(f\"Prediction: {prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deneme0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, EvalPrediction\n",
    "from datasets import Dataset\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data\n",
    "df = pd.read_csv(\"data.csv\")  \n",
    "df['text'] = df['text'].apply(lambda x: re.sub(r\"[^a-zA-ZığüşöçİĞÜŞÖÇ ]\",\"\",x).lower())\n",
    "# Split into train and test sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)  # random_state for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-cased\") # Türkçe BERT modelini kullan\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Fine-tuning\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"dbmdz/bert-base-turkish-cased\", num_labels=len(set(df[\"label\"]))) # Türkçe BERT modelini kullan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    num_train_epochs=5,  # Adjust as needed\n",
    "    per_device_train_batch_size=32,  # Adjust based on your GPU memory\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function to compute metrics\n",
    "def compute_metrics(pred: EvalPrediction):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets,\n",
    "    eval_dataset=tokenized_datasets, # Using same dataset for eval in this example\n",
    "    compute_metrics=compute_metrics, # Pass the metrics function to the Trainer\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the model\n",
    "trainer.save_model(\"./best-model\")\n",
    "\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "tokenized_test_dataset = test_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Evaluate on the test dataset\n",
    "results = trainer.predict(tokenized_test_dataset)\n",
    "predicted_labels = np.argmax(results.predictions, axis=1)\n",
    "accuracy = accuracy_score(test_df[\"label\"], predicted_labels)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_df = test_df\n",
    "diff_df['predicted'] = predicted_labels\n",
    "diff_df = diff_df[diff_df['label'] != diff_df['predicted']]\n",
    "diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_df.to_csv(\"false_predictions.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test_df\n",
    "df['predicted'] = predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(df['label'], df['predicted'])\n",
    "\n",
    "# Confusion matrix'i daha okunaklı hale getirmek için bir DataFrame'e dönüştürün\n",
    "cm_df = pd.DataFrame(cm, index=df['label'].unique(), columns=df['label'].unique())\n",
    "\n",
    "# Confusion matrix'i görüntüleyin\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Sınıflandırma raporunu yazdır\n",
    "print(classification_report(df['label'], df['predicted']))\n",
    "\n",
    "# Her sınıf için metrikleri hesapla\n",
    "accuracy = accuracy_score(df['label'], df['predicted'])\n",
    "precision = precision_score(df['label'], df['predicted'], average=None)\n",
    "recall = recall_score(df['label'], df['predicted'], average=None)\n",
    "f1 = f1_score(df['label'], df['predicted'], average=None)\n",
    "\n",
    "# Sonuçları yazdır\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"./best-model\")\n",
    "def preprocess_text(text):\n",
    "    return tokenizer(text, padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "import torch\n",
    "\n",
    "def predict(text):\n",
    "    inputs = preprocess_text(text)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "    return predictions.item()\n",
    "\n",
    "# Example usage\n",
    "text =\"\"\n",
    "prediction = predict(text)\n",
    "print(f\"Prediction: {prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deneme0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, EvalPrediction\n",
    "from datasets import Dataset\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data\n",
    "df = pd.read_csv(\"data.csv\")  \n",
    "df['text'] = df['text'].apply(lambda x: re.sub(r\"[^a-zA-Z ]\",\"\",x).lower())\n",
    "# Split into train and test sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)  # random_state for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\") # Use the smallest BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True,max_length=512)\n",
    "\n",
    "dataset = Dataset.from_pandas(train_df)\n",
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Fine-tuning\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(set(df[\"label\"]))) # Use the smallest BERT model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    num_train_epochs=3,  # Adjust as needed\n",
    "    per_device_train_batch_size=32,  # Adjust based on your GPU memory\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function to compute metrics\n",
    "def compute_metrics(pred: EvalPrediction):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets,\n",
    "    eval_dataset=tokenized_datasets, # Using same dataset for eval in this example\n",
    "    compute_metrics=compute_metrics, # Pass the metrics function to the Trainer\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the model\n",
    "trainer.save_model(\"./best-model\")\n",
    "\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "tokenized_test_dataset = test_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Evaluate on the test dataset\n",
    "results = trainer.predict(tokenized_test_dataset)\n",
    "predicted_labels = np.argmax(results.predictions, axis=1)\n",
    "accuracy = accuracy_score(test_df[\"label\"], predicted_labels)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_df = test_df\n",
    "diff_df['predicted'] = predicted_labels\n",
    "diff_df = diff_df[diff_df['label'] != diff_df['predicted']]\n",
    "diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_df.to_csv(\"false_predictions.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deneme0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
